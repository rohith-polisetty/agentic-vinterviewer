from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import sys
import os
from dotenv import load_dotenv

# Add project root to path to import agents
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from agents.graph import app_graph
from mcp_server.database import init_db
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage

load_dotenv()
init_db()

app = FastAPI(title="VIntervu 2.0 API")

class ResumeRequest(BaseModel):
    resume_text: str

class ChatRequest(BaseModel):
    message: str
    session_id: str
    candidate_profile: Optional[Dict[str, Any]] = None
    history: List[Dict[str, str]] = [] # Simple history: [{"role": "user", "content": "..."}]

class ChatResponse(BaseModel):
    response: str
    candidate_profile: Optional[Dict[str, Any]] = None
    code_output: Optional[str] = None

def dict_to_messages(history: List[Dict[str, str]]) -> List[BaseMessage]:
    messages = []
    for msg in history:
        if msg["role"] == "user":
            messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            messages.append(AIMessage(content=msg["content"]))
    return messages

@app.post("/analyze-resume", response_model=ChatResponse)
async def analyze_resume(request: ResumeRequest):
    try:
        initial_state = {
            "messages": [],
            "resume_text": request.resume_text,
            "candidate_profile": None
        }
        result = app_graph.invoke(initial_state)
        
        last_msg = result["messages"][-1]
        content = last_msg.content if isinstance(last_msg, BaseMessage) else str(last_msg)
        
        return ChatResponse(
            response=content,
            candidate_profile=result.get("candidate_profile")
        )
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    try:
        # Reconstruct state
        current_messages = dict_to_messages(request.history)
        current_messages.append(HumanMessage(content=request.message))
        
        initial_state = {
            "messages": current_messages,
            "candidate_profile": request.candidate_profile,
            "interview_stage": "introduction" if not request.candidate_profile else "technical", # Simplified logic
            "session_id": request.session_id
        }
        
        result = app_graph.invoke(initial_state)
        
        # Get the new response (last message)
        # Note: In a real app, we might get multiple new messages. For now, taking the last one.
        new_messages = result["messages"][len(current_messages)-1:] # -1 because we added one above
        # Actually, let's just take the very last message generated by the agent
        last_agent_msg = result["messages"][-1]
        content = last_agent_msg.content if isinstance(last_agent_msg, BaseMessage) else str(last_agent_msg)
        
        return ChatResponse(
            response=content,
            candidate_profile=result.get("candidate_profile"),
            code_output=result.get("code_output")
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
